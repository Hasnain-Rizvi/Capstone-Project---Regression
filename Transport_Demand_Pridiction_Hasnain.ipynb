{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "TNVZ9zx19K6k",
        "bmKjuQ-FpsJ3",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Transport Demand Pridiction**    - Regression\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Member 1 -**        Hasnain Mazhar Rizvi\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In brief, the project's goal is to construct a predictive model for Mobiticket that forecasts the seat sales for each trip based on particular routes, dates, and times. The trips initiate from 14 towns toward Lake Victoria and conclude in Nairobi. The travel duration is approximately 8 to 9 hours to reach the outskirts of Nairobi, followed by an additional 2 to 3 hours to the central bus terminal. Traffic conditions significantly affect passenger behavior during their journey to the city and onward to their final destinations in Nairobi. Gaining insights into these patterns can lead to better service planning and operational optimization for Mobiticket.\n",
        "\n",
        "To improve the model's effectiveness, additional features have been created. These new features aim to provide more pertinent information and contribute to more accurate predictions. The dataset has undergone testing using various regression models. These models were utilized to analyze the data and extract valuable insights, enabling a thorough assessment of the predictive capabilities. The most noteworthy features identified by the model are emphasized and presented. These critical features play a vital role in determining the number of seats sold for each trip. By showcasing these significant factors, stakeholders can develop a deeper understanding of the influential aspects that drive seat sales."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Hasnain-Rizvi/Capstone-Project---Regression.git"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This challenge asks you to build a model that predicts the number of seats that Mobiticket can expect to sell for each ride, i.e. for a specific route on a specific date and time. There are 14 routes in this dataset. All of the routes end in Nairobi and originate in towns to the North-West of Nairobi towards Lake Victoria.\n",
        "\n",
        "The towns from which these routes originate are:\n",
        "\n",
        "\n",
        "* Awendo\n",
        "* Homa Bay\n",
        "*Kehancha\n",
        "*Kendu Bay\n",
        "*Keroka\n",
        "*Keumbu\n",
        "*Kijauri\n",
        "*Kisii\n",
        "*Mbita\n",
        "*Migori\n",
        "*Ndhiwa\n",
        "*Nyachenge\n",
        "*Oyugis\n",
        "*Rodi\n",
        "*Rongo\n",
        "*Sirare\n",
        "*Sori\n",
        "\n",
        "\n",
        "The routes from these 14 origins to the first stop in the outskirts of Nairobi takes approximately 8 to 9 hours from time of departure. From the first stop in the outskirts of Nairobi into the main bus terminal, where most passengers get off, in Central Business District, takes another 2 to 3 hours depending on traffic.\n",
        "The three stops that all these routes make in Nairobi (in order) are:\n",
        "\n",
        "1. Kawangware: the first stop in the outskirts of Nairobi\n",
        "2. Westlands\n",
        "3. Afya Centre: the main bus terminal where most passengers disembark\n",
        "\n",
        "\n",
        "Passengers of these bus (or shuttle) rides are affected by Nairobi traffic not only during their ride into the city, but from there they must continue their journey to their final destination in Nairobi wherever that may be. Traffic can act as a deterrent for those who have the option to avoid buses that arrive in Nairobi during peak traffic hours. On the other hand, traffic may be an indication for peopleâ€™s movement patterns, reflecting business hours, cultural events, political events, and holidays."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Capstone Project 2- Regression/train_revised.csv')"
      ],
      "metadata": {
        "id": "ZFAbIqXywiOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "JgrSetAkxWNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "rows = df.count()[0]\n",
        "columns = len(df.columns)\n",
        "print('Rows are',rows)\n",
        "print('Columns are',columns)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ti_T6iF7zjcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "PGbHjQwEM3MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().value_counts()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Note : No Duplicate Values Found in Dataset.***"
      ],
      "metadata": {
        "id": "k6R7AgV01Gr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Note : No Null Values Found in Dataset.***"
      ],
      "metadata": {
        "id": "fXXJcd_x1i_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From Above Dataset :\n",
        "\n",
        "\n",
        "1.   The Dataset has 51645 Rows and 10 Columns.\n",
        "2.   There are no duplicate Values.\n",
        "3.   There are no Null/Missing Values.\n",
        "\n",
        "The Dataset is preety clean till now.\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='object')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* #### ride_id: unique ID of a vehicle on a specific route on a specific day and time.\n",
        "* #### seat_number: seat assigned to ticket\n",
        "* #### payment_method: method used by customer to purchase ticket from Mobiticket (cash or Mpesa)\n",
        "* #### payment_receipt: unique id number for ticket purchased from Mobiticket\n",
        "* #### travel_date: date of ride departure. (MM/DD/YYYY)\n",
        "* #### travel_time: scheduled departure time of ride. Rides generally depart on time. (hh:mm)\n",
        "* #### travel_from: town from which ride originated\n",
        "* #### travel_to: destination of ride. All rides are to Nairobi.\n",
        "* #### car_type: vehicle type (shuttle or bus)\n",
        "* #### max_capacity: number of seats on the vehicle"
      ],
      "metadata": {
        "id": "Fh5mweqm1fFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.describe(include='object').iloc[1,:]"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().iloc[1,:]"
      ],
      "metadata": {
        "id": "csjSjOcDQbGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df.head()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From our dataset Since we are not given the target variable so we need to find target variable first.**\n",
        "\n",
        "There might be many ways of finding the target variable but here we use one way that is we will find the count of each ride_id and that will be the number_of_ticket as our target variable."
      ],
      "metadata": {
        "id": "eQYQcJ6qRFHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking number of unique ride ids\n",
        "len(df['ride_id'].unique())"
      ],
      "metadata": {
        "id": "9xBlewoNSK7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making target variable 'number of ticket' by grouping the dataframe on ride_id column\n",
        "temp_df = df.groupby('ride_id')['seat_number'].count().reset_index()\n",
        "temp_df.rename(columns = {'seat_number':'number_of_ticket'},inplace=True)\n",
        "temp_df.head()"
      ],
      "metadata": {
        "id": "-XDvJqxgSNWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping unuseful columns\n",
        "\n",
        "df.drop(['seat_number','payment_method','payment_receipt','travel_to'],axis=1, inplace=True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "oEZuuJt9SnRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping duplicates\n",
        "df.drop_duplicates('ride_id',inplace=True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "ZWtXXlQ5S3YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging this new dataframe with orginal dataframe on column ride_id\n",
        "df = df.merge(temp_df, how='left', on='ride_id')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "psNgD-MaT4xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a column date_time which is a combination of columns travel_date and travel_time\n",
        "df['date_time'] = pd.to_datetime(df['travel_date'] +\" \"+ df['travel_time'])\n",
        "df['travel_date'] = pd.to_datetime(df['travel_date'])"
      ],
      "metadata": {
        "id": "AXg4qN17UIUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy = df.copy()"
      ],
      "metadata": {
        "id": "1lzSnGzaUO2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy"
      ],
      "metadata": {
        "id": "XLMf6MQhaBPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating additonal features with travel_date and travel_time columns\n",
        "\n",
        "#Creating a function to add the above features\n",
        "def create_date_cols(df_temp):\n",
        "  df_temp['travel_month'] = df_temp['travel_date'].dt.month\n",
        "  df_temp['travel_year'] = df_temp['travel_date'].dt.year\n",
        "  df_temp['travel_day_of_month'] = df_temp['travel_date'].dt.day\n",
        "  df_temp['travel_day_of_year'] = df_temp['travel_date'].dt.dayofyear\n",
        "  df_temp['travel_day_of_week'] = df_temp['travel_date'].dt.dayofweek\n",
        "  df_temp['travel_hour'] = pd.to_datetime(df_temp['travel_time']).dt.hour\n",
        "  df_temp['quarter'] = df_temp['travel_date'].dt.quarter\n",
        "  df_temp['is_weekend'] = df_temp['travel_day_of_week'].apply(lambda x: 1 if x in [5,6] else 0)\n",
        "\n",
        "  return df_temp\n",
        "\n",
        "#Applying function on our dataframe\n",
        "df_copy = create_date_cols(df_copy)"
      ],
      "metadata": {
        "id": "TMeuKW82UVw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.columns"
      ],
      "metadata": {
        "id": "YnYuwWMVUZkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.head()"
      ],
      "metadata": {
        "id": "6jaJR0ecUdT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting travel_time column into integer format\n",
        "df_copy['travel_time'] = df_copy['travel_time'].str.split(':').apply(lambda x: round(int(x[0]) + int(x[1])/60 ,2) )"
      ],
      "metadata": {
        "id": "wAcLx-lsUmPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating function that defines periods for time intervals\n",
        "def get_period(hour):\n",
        "  if hour<7: return 'em'\n",
        "  elif hour>=7 and hour<=11: return 'mor'\n",
        "  elif hour>11 and hour<=15: return 'an'\n",
        "  elif hour>15 and hour<=19: return 'evn'\n",
        "  elif hour>19 and hour<=24: return 'nght'\n",
        "\n",
        "df_copy['time_period_of_day'] = df_copy['travel_hour'].apply(get_period)"
      ],
      "metadata": {
        "id": "N0qWqBYsUrg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.head()"
      ],
      "metadata": {
        "id": "t2eTSRgNUtzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What all manipulations have you done and insights you found?**\n",
        "\n",
        "1. Created target variable 'number_of_ticket'\n",
        "2. Dropped constant and non essential columns\n",
        "3. Used travel_date and travel_time columns to extract and create datetime related features\n",
        "4. Created period feature from travel time for data visualization"
      ],
      "metadata": {
        "id": "AKPcreGjU8OW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_z38YNTUtfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "# Histogram for distribution of tickets\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df_copy['number_of_ticket'], color='orange')\n",
        "plt.title(\"Distribution of tickets\")"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It gives you clear intutive figure of number of tickets"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From data, usually number of tickets bought per ride_id is between 1 and 12"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No,its fine and it is right schewd too so its a positive side"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "IF9haa7NW_0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#Bar chart for types of transport used\n",
        "plt.figure(figsize=(10,6))\n",
        "df_copy['car_type'].value_counts().plot(kind='bar',color='teal')\n",
        "plt.title(\"Types of transport used\")\n",
        "plt.xlabel('Car Type')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "when  it comes to comparing bar graph gives real comparison."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of Buses and shuttle are nearly equal in the data. Hence, both type of cars are used equally for traveling."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No its no effect"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "#Bar chart for Max Capacities of transport\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=df_copy, x='car_type', y='max_capacity', color='red')\n",
        "plt.title(\"Max Capacities of Transport\")\n",
        "plt.xlabel('Max Capacity')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "when  it comes to comparing bar graph gives real comparison."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see Obviously buses have large capacity as compare to shuttle"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes we can see a path which kind of capacity will suite the route"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "#Bar chart for total number of ticket from each origin place\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=df_copy,x='travel_from',y='number_of_ticket', palette='viridis')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Total tickets from each origin place')\n",
        "plt.xlabel('Origin Place')\n",
        "plt.ylabel('Number of Tickets')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ease of Use,Aesthetic Appeal and Statistical Summary: sns.barplot can automatically calculate and display a summary statistic"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Most no. of tickets are sold from:\n",
        "\n",
        "    Sirare,  Mbita, Migori\n",
        "   \n",
        "While the least no. of tickets are sold from:\n",
        "\n",
        "    Keumbu, Kendu Bay"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes, we can know where we have to focus"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "#Monthwise Distribution of travellers\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df_copy['travel_month'],bins=12, color='teal')\n",
        "plt.title('Month wise distribution of travel')\n",
        "plt.xlabel('Months')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " provides a wide range of options for customizing the appearance of the histogram, including bin size, color,etc.."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostt of the traveling is done in the months of January, February and December."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see which month has most ticket sales"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "#Day of Monthwise Distribution of travellers\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df_copy['travel_day_of_month'],bins=12, color='teal')\n",
        "plt.title('Day of month wise distribution for travelling')\n",
        "plt.xlabel('Days of Month')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " provides a wide range of options for customizing the appearance of the histogram, including bin size, color,etc.."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostt of the traveling is done from before 5th of the month, there seems to be no travelling done between 5th and 11th of the month. This can be because of transport holiday during this period everry month."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes , getting know more"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "#Scatterplot of number of tickets sold for everyday of the month\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(data=df_copy, x='travel_day_of_month',y='number_of_ticket',color='teal')\n",
        "plt.title('Number of tickets for every day of month')"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Relationships Scatter plots are excellent for visualizing relationships between two variables."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarr to above graph, we can see there are no tickets sold between 5th and 11th of every month. Transport may^ be closed during this period every month because of tranport holidays."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes, as the holidays also affect the sales"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "\n",
        "#Scatterplot for number of tickets in every hour of day.\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(data=df_copy, x='travel_hour',y='number_of_ticket',color='teal')\n",
        "plt.title('Number of tickets for each hour of day')"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Relationships Scatter plots are excellent for visualizing relationships between two variables."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In, the day, most tickets are sold at 7AM and close to 7PM. This can be because people going to and returning from work in Nairobi at these times. Similarly, there are no tickets sold between 12PM and 5:30 PM."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yes, we have to take timing also in point."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "#Bar chart for Number of tickets for each period of day\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=df_copy, x='time_period_of_day',y='number_of_ticket', palette='viridis')\n",
        "plt.title('Number of tickets for each period of day')"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lowing to use DataFrame columns directly for plotting, making it convenient for data analysis workflows."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most number of tickets are sold in evening followed by morning hours."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "time is take in the account also."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.heatmap(df_copy.corr(),annot=True, cmap='viridis')"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " is used to create a heatmap with the specified data. The function provides a convenient way to visualize patterns in the data using colors"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can se weekend is very correlated to the weeks so more travel on weekends."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "sns.pairplot(df_copy, diag_kind='kde')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "is a handy tool for gaining a quick and comprehensive overview of the relationships and distributions within a dataset."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that weekend is very import in number of tickts and weeks is import and have a peak at no. of hours."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As per my observation, I have come to this conclusion till now.:**\n",
        "    \n",
        "There are no travel activities taking place during the afternoon.\n",
        "\n",
        "The quantity of buses utilized for travel matches the count of shuttles used.\n",
        "\n",
        "The highest ticket sales occur during the morning.\n",
        "\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis** : (H0) = No activity in after non\n",
        "\n",
        "**Alternative Hypothesis** :(H1) =activity in after non"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "sns.scatterplot(data=df_copy, x='travel_hour',y='number_of_ticket',color='teal')\n",
        "plt.title('Number of tickets for each hour of day')"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above we can see that between 12pm and 4pm (Afternoon), there are no travellers, or number of tickets sold are 0.\n",
        "\n",
        "Hence Na = 0, therefore we cannot reject Null Hypothesis."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Graphical representation is most good enough to get to know the result."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement: The number of buses used in traveling is same as the number of shuttle used. Let Number of buses used be Nb, and Number of shuttle used be Ns\n",
        "\n",
        "Null Hypothesis (H0) : Nb = Ns\n",
        "\n",
        "Arlternative Hypothesis (Ha) : Nb != Ns\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "df_copy['car_type'].value_counts().plot(kind='bar',color='teal')\n",
        "plt.title(\"Types of transport used\")\n",
        "plt.xlabel('Car Type')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above, Nb > Ns, hence we can reject Null Hypothesis."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Graphical representation is most good enough to get to know the result"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most number of tickets are sold in morning.\n",
        "\n",
        "Null Hypothesis : Most number of tickets are sold in morning\n",
        "\n",
        "Alternative Hypothesis : Most number of tickets are not sold in morning"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "sns.barplot(data=df_copy, x='time_period_of_day',y='number_of_ticket', palette='viridis')\n",
        "plt.title('Number of tickets for each period of day')"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above we can see, max tickets are sold in evening, hence we can reject null hypothesis"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar graphical representation gives that we are above p-value"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "df_copy.travel_month.value_counts()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.travel_day_of_year.value_counts()"
      ],
      "metadata": {
        "id": "iXg6wCk4SehG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.travel_day_of_month.value_counts()"
      ],
      "metadata": {
        "id": "pV8-kxEOShlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.time_period_of_day.value_counts()"
      ],
      "metadata": {
        "id": "_E3PzuxeSkPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above 3 value counts, we can see:\n",
        "1. Some months have higher frequency of travel\n",
        "1. Some days in year have very high frequency of travelers, while others have really low frequency. This is because of more traveling being done in some month than others.\n",
        "2. Some days in a month have high frequeny of travel than others.\n",
        "3. Some period in the day have high frequency of travel.\n",
        "\n",
        "To manage this, we will create a dictionary of the frequency for the 4 columns above and create 4 new columns taking log transform for the same."
      ],
      "metadata": {
        "id": "Blt0d3h9S57t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "period_dict = dict(df_copy.time_period_of_day.value_counts())\n",
        "df_copy['travel_hour_wise_weights'] = np.log1p(df_copy.time_period_of_day.map(period_dict))\n",
        "\n",
        "# Creating a seperate column for giving day of a year wise weights for the hours column\n",
        "day_of_year_dict = dict(df_copy.travel_day_of_year.value_counts())\n",
        "df_copy['travel_day_of_year_wise_weights'] = np.log1p(df_copy.travel_day_of_year.map(day_of_year_dict))\n",
        "\n",
        "# Giving weights to the each days of the month based on the frequency of ticket bookings\n",
        "day_of_month_wise_weights_dict = {2:1, 12:1, 3:1, 4:2, 1:3, 13:3, 14:3, 16:3, 28:3, 19:3, 18:3, 15:3, 17:3, 20:3, 22:4, 21:4, 27:4, 29:4, 23:4, 24:4, 26:4, 30:4, 25:4, 31:4}\n",
        "df_copy['travel_day_of_month_wise_weights'] = df_copy.travel_day_of_month.replace(day_of_month_wise_weights_dict)\n",
        "\n",
        "# Creating a column for giving weights to the each months of a year based on the frequency of ticket bookings\n",
        "travel_month_wise_weights_dict = {12: 1,\n",
        " 2: 1,\n",
        " 1: 1,\n",
        " 3: 1,\n",
        " 4: 1,\n",
        " 11: 2,\n",
        " 9: 3,\n",
        " 7: 3,\n",
        " 8: 3,\n",
        " 10: 3,\n",
        " 6: 3,\n",
        " 5: 3}\n",
        "df_copy['travel_month_wise_weights'] = df_copy.travel_month.replace(travel_month_wise_weights_dict)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.head(3)"
      ],
      "metadata": {
        "id": "VU0ODvR2TJ_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a method to create new features in df\n",
        "\n",
        "# Creating columns for time difference between next and previous buses for each of the origin places (travel_from).\n",
        "def find_difference_bw_bus(data):\n",
        "\n",
        "  data.sort_values([\"travel_from\",\"date_time\"],inplace=True,ascending=True)\n",
        "  data[\"Time_gap_btw_0_1_next_bus\"]=(data[\"date_time\"]-data.groupby([\"travel_from\"]).date_time.shift(-1)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_0_1_previous_bus\"]=(data[\"date_time\"]-data.groupby([\"travel_from\"]).date_time.shift(1)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_0_2_next_bus\"]=(data[\"date_time\"]-data.groupby([\"travel_from\"]).date_time.shift(-2)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_0_2_previous_bus\"]=(data[\"date_time\"]-data.groupby([\"travel_from\"]).date_time.shift(2)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_0_3_next_bus\"]=(data[\"date_time\"]-data.groupby([\"travel_from\"]).date_time.shift(-3)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_0_3_previous_bus\"]=(data[\"date_time\"]-data.groupby([\"travel_from\"]).date_time.shift(3)).dt.total_seconds()/3600\n",
        "  data[\"Time_gap_btw_next_previous_bus\"]=(data.groupby([\"travel_from\"]).date_time.shift(-1)-data.groupby([\"travel_from\"]).date_time.shift(1)).dt.total_seconds()/3600\n",
        "  cols=[\"Time_gap_btw_0_1_next_bus\", \"Time_gap_btw_0_1_previous_bus\", \"Time_gap_btw_0_2_next_bus\",\"Time_gap_btw_0_2_previous_bus\",\n",
        "      \"Time_gap_btw_0_3_next_bus\", \"Time_gap_btw_0_3_previous_bus\",\n",
        "      \"Time_gap_btw_next_previous_bus\"]\n",
        "\n",
        "  #Handling missing values\n",
        "  data[cols]=data.groupby([\"travel_from\"])[cols].fillna(method=\"ffill\")\n",
        "  data[cols]=data.groupby([\"travel_from\"])[cols].fillna(method=\"backfill\")\n",
        "\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "c9kESan3TMJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_data_new = find_difference_bw_bus(df_copy)"
      ],
      "metadata": {
        "id": "halFqIrsTOi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_data_new.groupby([\"travel_from\"]).date_time.shift(-1)"
      ],
      "metadata": {
        "id": "80Tn3buETR3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_data_new[['travel_from','date_time','Time_gap_btw_0_1_next_bus','Time_gap_btw_0_1_previous_bus']].head()"
      ],
      "metadata": {
        "id": "GNSAxoXbTT4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a dictionary containing distances of originating places from nairobi, taken from google maps\n",
        "distance_from_nairobi = {'Awendo':351, 'Homa Bay':360, 'Kehancha': 387.7, 'Keroka': 280, 'Keumbu':295, 'Kijauri':271,\n",
        "                         'Kisii':305.1, 'Mbita':401, 'Migori': 370, 'Ndhiwa': 371, 'Nyachenge':326, 'Rodi':348, 'Rongo':332,\n",
        "                         'Sirare':392, 'Sori':399}\n",
        "\n",
        "transport_data_new['distance_to_destination'] = transport_data_new['travel_from'].map(distance_from_nairobi)"
      ],
      "metadata": {
        "id": "QBRcfakpTXvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_data_new.columns"
      ],
      "metadata": {
        "id": "Gp1NL5ZuThae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use serverl numpy logic like np.log1p which Return the natural logarithm of one plus the input array element-wise.\n",
        "\n",
        "some pandas datafram logic seperation and selection coloumns etc.."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "as per our dataset it needs some extra exporting columns to determine the next fetures and ML alogrithms luike exporting gaps between the time and traffic gap."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "transport_data_new.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "only basic operation is enought to get the result.and we found some missing values ."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transport_data_new.dropna(inplace=True)\n",
        "transport_data_new.isnull().sum()"
      ],
      "metadata": {
        "id": "8Y_OwnEkbxVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transport_data_new.info()"
      ],
      "metadata": {
        "id": "ubxxMQ1M3qCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "def find_outliers_IQR(transport_data_new):\n",
        "\n",
        "   q1=transport_data_new.quantile(0.25)\n",
        "\n",
        "   q3=transport_data_new.quantile(0.75)\n",
        "\n",
        "   IQR=q3-q1\n",
        "\n",
        "   outliers = transport_data_new[((transport_data_new<(q1-1.5*IQR)) | (transport_data_new>(q3+1.5*IQR)))]\n",
        "\n",
        "   return outliers\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "od = find_outliers_IQR(transport_data_new['ride_id'])\n",
        "print(\"max outlier value: \"+ str(od.max()))\n",
        "print(\"min outlier value: \"+ str(od.min()))\n",
        "od"
      ],
      "metadata": {
        "id": "pxKS81nbwq8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "as per our data we can conclude to outlier because every data has some importans but we already remove missing values"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "from sklearn import preprocessing\n",
        "final_df = pd.get_dummies(df_copy, columns = ['travel_from','travel_day_of_month_wise_weights','travel_month_wise_weights'])"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Label encoding car_type column\n",
        "label_encoder = {'Bus':1,'shuttle':0}\n",
        "final_df.replace(label_encoder, inplace=True)\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "q2dh2yAL0ze9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have done one hot encoding on few categorical features, where label encoding on car_type"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "#Seperating target variable and indpendent features variable\n",
        "cols_to_drop = ['ride_id','travel_date','travel_time','max_capacity','travel_year','number_of_ticket','time_period_of_day','date_time','travel_month','travel_day_of_month','travel_day_of_year','travel_hour']\n",
        "X = final_df.drop(cols_to_drop,axis=1)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Target Variable\n",
        "y = final_df['number_of_ticket'].values\n",
        "y.shape"
      ],
      "metadata": {
        "id": "Hn8GeT131OxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5TDKWY3u1bCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "vd0d2N271e4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "Zmu_bhvm1hYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# i use 80%-20% for slipliting because thats the ideal way to do.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`As we have only intergers columns and remaining objective columns are already in good shape.`"
      ],
      "metadata": {
        "id": "e5aIao1HxCeq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`As we have only intergers columns and remaining objective columns are already in good shape.`"
      ],
      "metadata": {
        "id": "Xxusvq6HxW_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`As we have only intergers columns and remaining objective columns are already in good shape.`"
      ],
      "metadata": {
        "id": "IlJogD5mxaae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`As we have only intergers columns and remaining objective columns are already in good shape.`"
      ],
      "metadata": {
        "id": "CJCndXi9xeWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`There are no URL in our clean dataset`"
      ],
      "metadata": {
        "id": "Xeulwyt8xhuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`As we have only intergers columns and remaining objective columns are already in good shape.`"
      ],
      "metadata": {
        "id": "uEvRlPM5xprl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`As we have only intergers columns and remaining objective columns are already in good shape.`"
      ],
      "metadata": {
        "id": "lZrawAIaxtAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`As we have only intergers columns and remaining objective columns are already in good shape.`"
      ],
      "metadata": {
        "id": "o6hep-ItxvT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`As we have only intergers columns and remaining objective columns are already in good shape.`"
      ],
      "metadata": {
        "id": "b9Hiw63Txyfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, We dont need that"
      ],
      "metadata": {
        "id": "VxdgHnV6Z2OY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing required libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error,mean_absolute_percentage_error\n",
        "import math"
      ],
      "metadata": {
        "id": "85qznrZSCzW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating function for evaluation metrics\n",
        "def evaluate_metric(actual,predicted):\n",
        "  print('MSE is {}'.format(mean_squared_error(actual, predicted)))\n",
        "  print('RMSE is {}'.format(math.sqrt(mean_squared_error(actual, predicted))))\n",
        "  print('MAE is {}'.format(mean_absolute_error(actual, predicted)))\n",
        "  print('MAPE is {}'.format(np.mean(np.abs((actual - predicted) / actual)) * 100))\n",
        "  print('R2 Score is {}'.format(r2_score(actual, predicted)))"
      ],
      "metadata": {
        "id": "byQSik4fC3rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 (Linear Regression Algorithm)"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "regressor = LinearRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "regressor.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "y_train_pred = regressor.predict(X_train)\n",
        "\n",
        "y_test_pred = regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "#Train data evaluation\n",
        "evaluate_metric(y_train,y_train_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_train), (y_train_pred)))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_metric(y_test,y_test_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_test_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "AFDIuN9tEvcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression is not giving good results on data, hence trying regularized linear regression models**"
      ],
      "metadata": {
        "id": "xO1j9DlKE1SH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 - (***Lasso Algorithm***)"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "lasso  = Lasso(alpha=0.1 , max_iter= 3000)\n",
        "\n",
        "# Fit the Algorithm\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_train_pred = lasso.predict(X_train)\n",
        "\n",
        "y_test_pred = lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "7zaatNFRFiIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Train data evaluation\n",
        "evaluate_metric(y_train,y_train_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_train), (y_train_pred)))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data evaluation\n",
        "evaluate_metric(y_test,y_test_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_test_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "-mbCRxbMGPvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "-Br7pkFMho5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "lasso_regressor.fit(X, y)\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)\n",
        "\n",
        "# Predict on the model\n",
        "y_train_pred = lasso_regressor.predict(X_train)\n",
        "\n",
        "y_test_pred = lasso_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data evaluation\n",
        "evaluate_metric(y_train,y_train_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_train), (y_train_pred)))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))"
      ],
      "metadata": {
        "id": "1q-m9k_-iTRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data evaluation\n",
        "evaluate_metric(y_test,y_test_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_test_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "MwSNKLl9iXYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is used to tune hyperparameter, The best fit alpha value is found out to be : {'alpha': 0.01}"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has accuracy has decreased overall and does not give good results."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "on further algorith we can come to the conclusion."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 (***Ridge Algorithm***)"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "ridge = Ridge()\n",
        "\n",
        "# Fit the Algorithm\n",
        "ridge.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_train_pred = ridge.predict(X_train)\n",
        "\n",
        "y_test_pred = ridge.predict(X_test)"
      ],
      "metadata": {
        "id": "Ebe-Zo6Yfplp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric."
      ],
      "metadata": {
        "id": "ELuC4zghfwuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data evaluation\n",
        "evaluate_metric(y_train,y_train_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_train), (y_train_pred)))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))"
      ],
      "metadata": {
        "id": "C4i5uoa1fyhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data evaluation\n",
        "evaluate_metric(y_test,y_test_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_test_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "KSXwFy4Af48K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques\n",
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "\n",
        "# Fit the Algorithm\n",
        "ridge_regressor.fit(X,y)\n",
        "\n",
        "# Predict on the model\n",
        "y_train_pred = ridge_regressor.predict(X_train)\n",
        "\n",
        "y_test_pred = ridge_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data evaluation\n",
        "evaluate_metric(y_train,y_train_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_train), (y_train_pred)))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))"
      ],
      "metadata": {
        "id": "TPqZ4eDtrNaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data evaluation\n",
        "evaluate_metric(y_test,y_test_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_test_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "xrKAxoh3rorc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`GridSearchCV is used to tune hyperparameter, The best fit alpha value is found out to be : {'alpha': 1}`"
      ],
      "metadata": {
        "id": "LfQD6rUJgYxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`GridSearchCV has little effect on L2 Regression, has not changed the model accuracy much and overfitting still exists.`"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *As the required result we didnt get so we have to try Non linear regression also.*\n",
        "---"
      ],
      "metadata": {
        "id": "Mpz9vDUzj_P_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 4 (***Random Forest Algorithm***)"
      ],
      "metadata": {
        "id": "JS6aKLtOuoOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rfr = RandomForestRegressor()\n",
        "\n",
        "# Fit the Algorithm\n",
        "rfr.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_train_pred = rfr.predict(X_train)\n",
        "\n",
        "y_test_pred = rfr.predict(X_test)"
      ],
      "metadata": {
        "id": "LpM7sTozvQl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "mut1CD1cvY8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data evaluation\n",
        "evaluate_metric(y_train,y_train_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_train), (y_train_pred)))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))"
      ],
      "metadata": {
        "id": "ROV449T3veNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data evaluation\n",
        "evaluate_metric(y_test,y_test_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_test_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "qnWH_KS5vkM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks like the model causes overfitting, hence trying hyperparameter tuning.**"
      ],
      "metadata": {
        "id": "RTByBkBwvq0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "W5e2j2_Mv_ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rfr = RandomForestRegressor()\n",
        "from pprint import pprint\n",
        "# Look at parameters used by our current forest\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(rfr.get_params())\n",
        ""
      ],
      "metadata": {
        "id": "4tPK-ynX0FSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation with hyperparameter optimization techniques\n",
        "n_estimators = [int(x) for x in np.linspace(start = 400, stop = 1000, num = 4)]\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(40, 100, num = 4)]\n",
        "max_depth.append(None)\n",
        "\n",
        "# Create the parameters grid\n",
        "grid_params_dict = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth\n",
        "                    }\n",
        "print(grid_params_dict)"
      ],
      "metadata": {
        "id": "J5a_dtsXIsG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfr = RandomForestRegressor()\n",
        "\n",
        "# Grid Search of parameters, using 3 fold cross validation,\n",
        "rf_gridCV = GridSearchCV(estimator = rfr, param_grid = grid_params_dict, cv = 3, verbose=2, n_jobs = -1)\n",
        "\n",
        "# Fit the Algorithm\n",
        "rf_gridCV.fit(X,y)\n",
        "\n",
        "\n",
        "print(rf_gridCV.best_params_)"
      ],
      "metadata": {
        "id": "t2G-3I-yzwnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_gridCV.best_estimator_"
      ],
      "metadata": {
        "id": "Zyz1-mKOxMRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Taking best params and creating a new regressor\n",
        "rf_grid_optimal_model =rf_gridCV.best_estimator_\n",
        "\n",
        "# Predict on the model\n",
        "y_train_pred = rf_grid_optimal_model.predict(X_train)\n",
        "\n",
        "y_test_pred = rf_grid_optimal_model.predict(X_test)"
      ],
      "metadata": {
        "id": "ko9IXmsuxQ0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data evaluation\n",
        "evaluate_metric(y_train,y_train_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_train), (y_train_pred)))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))"
      ],
      "metadata": {
        "id": "B8BG_y1oxT5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data evaluation\n",
        "evaluate_metric(y_test,y_test_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_test_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "15eF3k5jxWn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "jXEDEui8xbtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is used to tune hyperparameter, The best hyperparameter values are:\n",
        "{'max_depth': 40, 'n_estimators': 400}"
      ],
      "metadata": {
        "id": "K5lHVeeDxgDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "n8acDRUnxxGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using GridSearchCV, the training accuracy have increase slightly, but the test accuracy has increased a lot, hence, the problem of overfitting which was faced in train_test_split method is removed."
      ],
      "metadata": {
        "id": "kPIoux8dx3Kd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 5 (***XGBoost Algorithm***)"
      ],
      "metadata": {
        "id": "cfGB3oKXwDEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 5 Implementation\n",
        "import xgboost as xgb\n",
        "xgbr = xgb.XGBRegressor()\n",
        "\n",
        "# Fit the Algorithm\n",
        "xgbr.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_train_pred = xgbr.predict(X_train)\n",
        "\n",
        "y_test_pred = xgbr.predict(X_test)"
      ],
      "metadata": {
        "id": "mN1jqKhLwR-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "d-KmVkFJwXAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data evaluation\n",
        "evaluate_metric(y_train,y_train_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_train), (y_train_pred)))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))"
      ],
      "metadata": {
        "id": "W3Z5a9_0wZS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data evaluation\n",
        "evaluate_metric(y_test,y_test_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_test_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "K9tIqvAywcij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks like the model causes overfitting, hence trying hyperparameter tuning.**"
      ],
      "metadata": {
        "id": "AeV-aEdSyaSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "RTQ1mGjayfoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 5 Implementation with hyperparameter optimization techniques\n",
        "n_estimators = [int(x) for x in np.linspace(start = 400, stop = 1000, num = 4)]\n",
        "\n",
        "max_depth= [6, 8, 10, 12]\n",
        "min_child_weight= [7, 8, 10, 12]\n",
        "\n",
        "# Create the random grid\n",
        "xgb_grid_params_dict = {\n",
        "         'max_depth': max_depth,\n",
        "         'min_child_weight': min_child_weight\n",
        "                         }\n",
        "print(xgb_grid_params_dict)\n",
        "\n",
        "\n",
        "xgbr = xgb.XGBRegressor(objective='reg:squarederror', random_state = 3)\n",
        "\n",
        "# Grid Search of parameters, using 3 fold cross validation,\n",
        "xgbr_grid = GridSearchCV(estimator = xgbr, param_grid = xgb_grid_params_dict, cv = 3, verbose=2, n_jobs = -1)\n",
        "\n",
        "# Fit the Algorithm\n",
        "xgbr_grid.fit(X,y)\n",
        "\n",
        "\n",
        "print(xgbr_grid.best_params_)"
      ],
      "metadata": {
        "id": "y0T0IXhjymrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgbr_grid.best_estimator_"
      ],
      "metadata": {
        "id": "HoeCKGzyytBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Taking best params and creating a new regressor\n",
        "xgbr_optimal_model =xgbr_grid.best_estimator_\n",
        "\n",
        "# Predict on the model\n",
        "y_train_pred = xgbr_optimal_model.predict(X_train)\n",
        "\n",
        "y_test_pred = xgbr_optimal_model.predict(X_test)"
      ],
      "metadata": {
        "id": "0ph3cPWoywC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data evaluation\n",
        "evaluate_metric(y_train,y_train_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_train), (y_train_pred)))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))"
      ],
      "metadata": {
        "id": "nnLihMtzyzM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data evaluation\n",
        "evaluate_metric(y_test,y_test_pred)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_test_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "dRc3eorCzGvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "EyE5bVE1zSuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is used to tune hyperparameter, The best fit values are found out to be : {'max_depth': 6, 'min_child_weight': 8}"
      ],
      "metadata": {
        "id": "PJnNwziGzW_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "n_aZoc-BzbYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using GridSearchCV, the training accuracy have increase slightly, but the test accuracy has increased a lot, hence, the problem of overfitting which was faced in train_test_split method is removed."
      ],
      "metadata": {
        "id": "D4cg8Q3szgm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following evalutation metrics were chosen:\n",
        "1. Mean Squared Error (MSE)\n",
        "2. Root Mean Squared Error (RMSE)\n",
        "3. Mean Absolute Error (MAE)\n",
        "4. Mean Absolute Percentage Error (MAPE)\n",
        "5. R2 Score\n",
        "6. Adjusted R2 Score"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Prediction Model : Random Forest (GridSearchCV) (Params: {'max_depth': 40, 'n_estimators': 600} )\n",
        "\n",
        "Performance on test data:\n",
        "- R2 Score : 0.944\n",
        "- Adjusted R2 :  0.943"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting most important features from final prediction model\n",
        "importances = rf_grid_optimal_model.feature_importances_"
      ],
      "metadata": {
        "id": "Gp2eUNnj2AM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a dictionary with all the important features\n",
        "importance_dict = {'Feature' : list(X_train.columns), 'Feature Importance' : importances}\n",
        "\n",
        "#Creating a dataframe from the dictionary of important features\n",
        "importance_df = pd.DataFrame(importance_dict)\n",
        "\n",
        "#Sorting features inside df by feature importance in descending order\n",
        "important_features=importance_df.sort_values(by=['Feature Importance'],ascending=False).head(20)"
      ],
      "metadata": {
        "id": "tPci50C62A4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a printing the list of important features\n",
        "imp_features = important_features['Feature'].tolist()\n",
        "print(f\"Import Features are: {imp_features}\")"
      ],
      "metadata": {
        "id": "mVa8ixqd2Fnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the important fetures obtainind from the optimal RF model\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "sns.barplot(x = 'Feature Importance', y = 'Feature', data=important_features, palette= 'viridis')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Feature Importance')"
      ],
      "metadata": {
        "id": "ufd40VmZ2IJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our project, we employed diverse regression techniques to forecast transportation demand from different locations to Nairobi.\n",
        "\n",
        "Utilizing the available data, we engineered both the target variable and several other features crucial for enhancing our model's predictive performance.\n",
        "\n",
        "The regression models encompassed both linear and non-linear approaches. Specifically, we utilized linear models such as :\n",
        "\n",
        "*   Linear Regression\n",
        "*   Lasso (L1)\n",
        "*   Ridge (L2)\n",
        "\n",
        "As well as non-linear models like :\n",
        "\n",
        "*   Random Forest\n",
        "*   XGBoos\n",
        "\n",
        "To optimize the models further, we conducted **Hyperparameter tuning**. Notably, after this tuning process, the **Random Forest model** demonstrated superior performance, achieving an impressive accuracy level of approximately 95%.\""
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}